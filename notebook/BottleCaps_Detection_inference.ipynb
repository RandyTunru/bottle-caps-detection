{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f14c2830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ultralytics onnxruntime numpy opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5faadf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import cv2 \n",
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5afadc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PT_PATH = '../model/best.pt'\n",
    "\n",
    "DATASET_YAML_PATH = '../bottle_cap_dataset/dataset.yaml'\n",
    "\n",
    "MODEL_ONNX_PATH = '../model/best.onnx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c03c8b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.228  Python-3.10.19 torch-2.2.2+cu121 CPU (AMD Ryzen 9 5900HS with Radeon Graphics)\n",
      "YOLO11n summary (fused): 100 layers, 2,582,737 parameters, 0 gradients, 6.3 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\model\\best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 7, 8400) (5.2 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.19.1 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.74...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  8.3s, saved as '..\\model\\best.onnx' (10.1 MB)\n",
      "\n",
      "Export complete (9.3s)\n",
      "Results saved to \u001b[1mC:\\Users\\randy\\Development\\Computer Vision Projects\\bottle_cap_detection\\model\u001b[0m\n",
      "Predict:         yolo predict task=detect model=..\\model\\best.onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=..\\model\\best.onnx imgsz=640 data=/content/bottle_caps_detection/bottle_cap_dataset/dataset.yaml  \n",
      "Visualize:       https://netron.app\n",
      "\n",
      "Successfully exported and saved to: ../model/best.onnx\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(MODEL_PT_PATH)\n",
    "\n",
    "try:\n",
    "    model.export(\n",
    "        format='onnx',\n",
    "        imgsz=640,\n",
    "        device='cpu'   \n",
    "    )\n",
    "    exported_original_path = MODEL_PT_PATH.replace('.pt', '.onnx')\n",
    "    os.rename(exported_original_path, MODEL_ONNX_PATH)\n",
    "    \n",
    "    print(f\"\\nSuccessfully exported and saved to: {MODEL_ONNX_PATH}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn error occurred during export: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16795307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Input Shape: [1, 3, 640, 640]\n",
      "Loading and pre-processing test image...\n",
      "Running warm-up (20 inferences)\n",
      "Running benchmark (100 inferences)\n",
      "\n",
      "ONNX Runtime Benchmark Results\n",
      "Total time for 100 inferences: 9.42 seconds\n",
      "Average inference time: 94.23 ms\n",
      "Frames Per Second (FPS): 10.61\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "try:\n",
    "    session = ort.InferenceSession(MODEL_ONNX_PATH, providers=['CPUExecutionProvider']) \n",
    "\n",
    "    input_name = session.get_inputs()[0].name\n",
    "    input_shape = session.get_inputs()[0].shape  \n",
    "    input_height = input_shape[2]\n",
    "    input_width = input_shape[3]\n",
    "    \n",
    "    print(f\"Model Input Shape: {input_shape}\")\n",
    "\n",
    "    print(\"Loading and pre-processing test image...\")\n",
    "    test_image_path = \"../bottle_cap_dataset/images/val/raw-250110_dc_s001_b2_3.jpg\" \n",
    "    \n",
    "    if not os.path.exists(test_image_path):\n",
    "        print(f\"ERROR: Test image not found at {test_image_path}\")\n",
    "    else:\n",
    "        image = cv2.imread(test_image_path)\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        resized = cv2.resize(image_rgb, (input_width, input_height))\n",
    "        \n",
    "        preprocessed_image = (resized / 255.0).transpose(2, 0, 1).astype(np.float32)\n",
    "        \n",
    "        # Add a batch dimension (B, C, H, W)\n",
    "        input_tensor = np.expand_dims(preprocessed_image, axis=0)\n",
    "\n",
    "        print(\"Running warm-up (20 inferences)\")\n",
    "        for _ in range(20):\n",
    "            session.run(None, {input_name: input_tensor})\n",
    "\n",
    "        num_runs = 100\n",
    "        print(f\"Running benchmark ({num_runs} inferences)\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        for _ in range(num_runs):\n",
    "            session.run(None, {input_name: input_tensor})\n",
    "        end_time = time.time()\n",
    "\n",
    "        total_time = end_time - start_time\n",
    "        avg_time_ms = (total_time / num_runs) * 1000\n",
    "        fps = 1000 / avg_time_ms\n",
    "\n",
    "        print(\"\\nONNX Runtime Benchmark Results\")\n",
    "        print(f\"Total time for {num_runs} inferences: {total_time:.2f} seconds\")\n",
    "        print(f\"Average inference time: {avg_time_ms:.2f} ms\")\n",
    "        print(f\"Frames Per Second (FPS): {fps:.2f}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error during ONNX benchmark: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
